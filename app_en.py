import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
import json
from datetime import datetime, timedelta
from pathlib import Path
import base64
import io

# æ—¢å­˜ã®ç«¶é¦¬AIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from horse_racing_ai_refactored import (
    HorseRacingPredictor,
    ResultsAnalyzer,
    list_saved_models,
    load_best_model
)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸ Horse Racing AI Prediction System",
    page_icon="ğŸ‡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    .feature-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
        margin-bottom: 1rem;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #667eea, #764ba2);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
    }
    
    .success-message {
        background: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #c3e6cb;
    }
    
    .error-message {
        background: #f8d7da;
        color: #721c24;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #f5c6cb;
    }
    
    .info-message {
        background: #d1ecf1;
        color: #0c5460;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #bee5eb;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
if 'predictor' not in st.session_state:
    st.session_state.predictor = None
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'training_progress' not in st.session_state:
    st.session_state.training_progress = 0
if 'prediction_results' not in st.session_state:
    st.session_state.prediction_results = None

def main():
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ Horse Racing AI Prediction System</h1>
        <p>Machine Learning Horse Race Prediction System - Powered by LightGBM & Optuna</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.markdown("## ğŸ”§ System Settings")
        
        # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
        mode = st.radio(
            "Select Operation Mode",
            ["ğŸ¯ Prediction Mode", "ğŸ‹ï¸ Training Mode", "ğŸ“Š Analysis Mode"],
            help="Prediction Mode: Predict with trained model\nTraining Mode: Train new model\nAnalysis Mode: Result analysis & comparison"
        )
        
        st.markdown("---")
        
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¡¨ç¤º
        st.markdown("### ğŸ“‹ System Status")
        if st.session_state.model_loaded:
            st.success("âœ… Model Loaded")
        else:
            st.warning("âš ï¸ Model Not Loaded")
        
        if st.session_state.predictor is not None:
            st.info(f"ğŸ¤– Prediction System: Ready")
        else:
            st.error("âŒ Prediction System: Not Initialized")
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if mode == "ğŸ¯ Prediction Mode":
        prediction_mode()
    elif mode == "ğŸ‹ï¸ Training Mode":
        training_mode()
    elif mode == "ğŸ“Š Analysis Mode":
        analysis_mode()

def prediction_mode():
    """äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®UI"""
    st.markdown("## ğŸ¯ Prediction Mode")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ‡ Race Prediction</h3>
            <p>Predict race outcomes using trained models</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        if st.button("ğŸ”„ Auto Load Model", type="primary", use_container_width=True):
            load_model_automatically()
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿çŠ¶æ…‹ã®ãƒã‚§ãƒƒã‚¯
    if not st.session_state.model_loaded:
        st.markdown("""
        <div class="info-message">
            <h4>ğŸ“¥ Model Loading Required</h4>
            <p>Please load a trained model before starting predictions.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§
        show_available_models()
        return
    
    # äºˆæ¸¬å®Ÿè¡ŒUI
    st.markdown("### ğŸ¯ Execute Race Prediction")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        race_id = st.text_input(
            "Race ID",
            value="202501010101",
            help="Enter netkeiba race ID (e.g., 202501010101)"
        )
    
    with col2:
        race_date = st.date_input(
            "Race Date",
            value=datetime(2025, 1, 1),
            help="Select race date"
        )
    
    with col3:
        st.markdown("<br>", unsafe_allow_html=True)
        if st.button("ğŸš€ Execute Prediction", type="primary", use_container_width=True):
            execute_prediction(race_id, race_date.strftime('%Y/%m/%d'))
    
    # äºˆæ¸¬çµæœã®è¡¨ç¤º
    if st.session_state.prediction_results is not None:
        display_prediction_results()

def training_mode():
    """å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã®UI"""
    st.markdown("## ğŸ‹ï¸ Training Mode")
    
    st.markdown("""
    <div class="feature-card">
        <h3>ğŸ“ New Model Training</h3>
        <p>Train new model using Optuna hyperparameter optimization</p>
    </div>
    """, unsafe_allow_html=True)
    
    # è¨“ç·´è¨­å®š
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### âš™ï¸ Training Settings")
        
        n_trials = st.slider(
            "Optuna Trials",
            min_value=10,
            max_value=200,
            value=50,
            step=10,
            help="Number of hyperparameter optimization trials (more = better accuracy, longer time)"
        )
        
        data_path = st.text_input(
            "Data File Path",
            value="data/data/results.pickle",
            help="Path to training data file"
        )
        
        use_optuna = st.checkbox(
            "Use Optuna Optimization",
            value=True,
            help="Enable automatic hyperparameter optimization"
        )
    
    with col2:
        st.markdown("### ğŸ“‹ Data Information")
        
        if Path(data_path).exists():
            st.success("âœ… Data File Found")
            file_size = Path(data_path).stat().st_size / (1024*1024)
            st.info(f"ğŸ“¦ File Size: {file_size:.1f} MB")
        else:
            st.error("âŒ Data File Not Found")
        
        # äºˆæƒ³è¨“ç·´æ™‚é–“
        estimated_time = estimate_training_time(n_trials)
        st.info(f"â±ï¸ Estimated Training Time: {estimated_time}")
    
    # è¨“ç·´å®Ÿè¡Œ
    st.markdown("---")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        if st.button("ğŸš€ Start Training", type="primary", use_container_width=True):
            if Path(data_path).exists():
                execute_training(data_path, n_trials, use_optuna)
            else:
                st.error("âŒ Data file does not exist")

def analysis_mode():
    """åˆ†æãƒ¢ãƒ¼ãƒ‰ã®UI"""
    st.markdown("## ğŸ“Š Analysis Mode")
    
    tabs = st.tabs(["ğŸ“ˆ Model Comparison", "ğŸ’° Return Analysis", "ğŸ“‹ Prediction History", "ğŸ” System Diagnostics"])
    
    with tabs[0]:
        model_comparison_tab()
    
    with tabs[1]:
        return_analysis_tab()
    
    with tabs[2]:
        prediction_history_tab()
    
    with tabs[3]:
        system_diagnostics_tab()

def load_model_automatically():
    """ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•èª­ã¿è¾¼ã¿"""
    with st.spinner("ğŸ” Searching for optimal model..."):
        try:
            # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢
            models_info = list_saved_models('.')
            
            if not models_info:
                st.error("âŒ No saved models found")
                return
            
            # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
            latest_model = models_info[0]
            model_path = latest_model['model_file'].replace('_model.pkl', '.pkl')
            
            st.info(f"ğŸ“‚ Loading: {latest_model['base_name']}")
            
            # äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
            st.session_state.predictor = HorseRacingPredictor()
            
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
            success = st.session_state.predictor.load_model(model_path)
            
            if success:
                st.session_state.model_loaded = True
                st.success("âœ… Model loaded successfully!")
                st.rerun()
            else:
                st.error("âŒ Failed to load model")
                
        except Exception as e:
            st.error(f"âŒ Error: {str(e)}")

def show_available_models():
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§è¡¨ç¤º"""
    st.markdown("### ğŸ“‚ Available Models")
    
    models_info = list_saved_models('.')
    
    if not models_info:
        st.warning("No saved models available. Please create a new model in Training Mode.")
        return
    
    # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã§è¡¨ç¤º
    model_df = pd.DataFrame([
        {
            "Model Name": info['base_name'],
            "Created": info['modified'].strftime('%Y-%m-%d %H:%M'),
            "Size": f"{info['size']:,} bytes",
            "Trained": "âœ…" if info.get('is_trained', False) else "âŒ",
            "Integrity": "âœ…" if info['has_info'] and info['has_state'] else "âš ï¸"
        }
        for info in models_info
    ])
    
    st.dataframe(model_df, use_container_width=True)
    
    # å€‹åˆ¥èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
    if st.button("ğŸ”½ Select Individual Model"):
        selected_model = st.selectbox(
            "Select model to load",
            options=[info['base_name'] for info in models_info]
        )
        
        if st.button("ğŸ“¥ Load Selected Model"):
            selected_info = next(info for info in models_info if info['base_name'] == selected_model)
            model_path = selected_info['model_file'].replace('_model.pkl', '.pkl')
            
            with st.spinner("Loading..."):
                st.session_state.predictor = HorseRacingPredictor()
                success = st.session_state.predictor.load_model(model_path)
                
                if success:
                    st.session_state.model_loaded = True
                    st.success("âœ… Model loaded successfully!")
                    st.rerun()
                else:
                    st.error("âŒ Failed to load model")

def execute_prediction(race_id, race_date):
    """äºˆæ¸¬å®Ÿè¡Œ"""
    if st.session_state.predictor is None:
        st.error("âŒ Prediction system not initialized")
        return
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("ğŸ” Fetching race data...")
        progress_bar.progress(25)
        
        # äºˆæ¸¬å®Ÿè¡Œ
        results = st.session_state.predictor.predict_race_live(race_id, race_date)
        progress_bar.progress(75)
        
        if results is not None:
            st.session_state.prediction_results = {
                'race_id': race_id,
                'race_date': race_date,
                'results': results,
                'timestamp': datetime.now()
            }
            
            progress_bar.progress(100)
            status_text.text("âœ… Prediction completed!")
            time.sleep(1)
            progress_bar.empty()
            status_text.empty()
            
        else:
            st.error("âŒ Prediction failed. Please check race ID or date.")
            progress_bar.empty()
            status_text.empty()
            
    except Exception as e:
        st.error(f"âŒ An error occurred: {str(e)}")
        progress_bar.empty()
        status_text.empty()

def display_prediction_results():
    """äºˆæ¸¬çµæœã®è¡¨ç¤º"""
    results_data = st.session_state.prediction_results
    
    st.markdown("## ğŸ¯ Prediction Results")
    
    # ãƒ¬ãƒ¼ã‚¹æƒ…å ±
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h4>ğŸ‡ Race ID</h4>
            <h2>{}</h2>
        </div>
        """.format(results_data['race_id']), unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h4>ğŸ“… Race Date</h4>
            <h2>{}</h2>
        </div>
        """.format(results_data['race_date']), unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
            <h4>ğŸ Runners</h4>
            <h2>{}</h2>
        </div>
        """.format(len(results_data['results'])), unsafe_allow_html=True)
    
    with col4:
        top_score = results_data['results'].iloc[0]['score']
        confidence = "High" if top_score > 0.6 else "Medium" if top_score > 0.4 else "Low"
        st.markdown("""
        <div class="metric-card">
            <h4>ğŸ¯ Confidence</h4>
            <h2>{}</h2>
        </div>
        """.format(confidence), unsafe_allow_html=True)
    
    # äºˆæ¸¬çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    st.markdown("### ğŸ“Š Prediction Ranking")
    
    results_df = results_data['results'].copy()
    results_df['Rank'] = range(1, len(results_df) + 1)
    results_df['Recommendation'] = results_df['score'].apply(lambda x: 
        "ğŸ”¥ Strong Buy" if x > 0.6 else "ğŸ“ˆ Buy" if x > 0.4 else "âš ï¸ Caution" if x > 0.2 else "âŒ Avoid"
    )
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    display_df = results_df[['Rank', 'é¦¬ç•ª', 'score', 'Recommendation']].copy()
    display_df['Score'] = display_df['score'].round(4)
    display_df = display_df[['Rank', 'é¦¬ç•ª', 'Score', 'Recommendation']]
    
    st.dataframe(
        display_df.head(10),
        use_container_width=True,
        hide_index=True
    )
    
    # äºˆæ¸¬ã‚¹ã‚³ã‚¢åˆ†å¸ƒã‚°ãƒ©ãƒ•
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“ˆ Score Distribution")
        fig = px.histogram(
            results_df,
            x='score',
            nbins=15,
            title="Prediction Score Distribution",
            color_discrete_sequence=['#667eea']
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### ğŸ¯ Top Horses Score")
        top5 = results_df.head(5)
        fig = px.bar(
            top5,
            x='é¦¬ç•ª',
            y='score',
            title="Top 5 Horses Prediction Scores",
            color='score',
            color_continuous_scale='Viridis'
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # æŠ•è³‡æ¨å¥¨
    st.markdown("### ğŸ’° Investment Recommendation")
    
    top_horse = results_df.iloc[0]
    if top_horse['score'] > 0.6:
        recommendation = "ğŸ”¥ **Strong Recommendation**: High probability of good performance expected"
        color = "success"
    elif top_horse['score'] > 0.4:
        recommendation = "ğŸ“ˆ **Recommendation**: Moderate probability of good performance expected"
        color = "info"
    else:
        recommendation = "âš ï¸ **Caution**: Low probability. Careful judgment recommended"
        color = "warning"
    
    if color == "success":
        st.success(recommendation)
    elif color == "info":
        st.info(recommendation)
    else:
        st.warning(recommendation)
    
    # è©³ç´°æƒ…å ±ã®è¡¨ç¤ºï¼ˆå±•é–‹å¯èƒ½ï¼‰
    with st.expander("ğŸ“‹ Detailed Information"):
        st.markdown("#### ğŸ All Runners Data")
        st.dataframe(results_df, use_container_width=True)
        
        # çµæœã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹
        json_data = {
            'race_id': results_data['race_id'],
            'race_date': results_data['race_date'],
            'predictions': results_df.to_dict('records'),
            'timestamp': results_data['timestamp'].isoformat()
        }
        
        st.download_button(
            label="ğŸ“¥ Download Results as JSON",
            data=json.dumps(json_data, ensure_ascii=False, indent=2),
            file_name=f"prediction_{results_data['race_id']}.json",
            mime="application/json"
        )

def execute_training(data_path, n_trials, use_optuna):
    """è¨“ç·´å®Ÿè¡Œ"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("ğŸ”§ Initializing prediction system...")
        st.session_state.predictor = HorseRacingPredictor()
        progress_bar.progress(10)
        
        status_text.text("ğŸ“š Loading data...")
        progress_bar.progress(20)
        
        if use_optuna:
            status_text.text(f"ğŸš€ Starting Optuna optimization ({n_trials} trials)...")
            progress_bar.progress(30)
            
            # è¨“ç·´å®Ÿè¡Œ
            success = st.session_state.predictor.train_model(data_path, n_trials=n_trials)
        else:
            status_text.text("ğŸ‹ï¸ Training with conventional method...")
            success = st.session_state.predictor.trainer.train(data_path)
            st.session_state.predictor.is_trained = True
        
        progress_bar.progress(80)
        
        if success:
            status_text.text("ğŸ’¾ Saving model...")
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            model_name = f"trained_model_{timestamp}.pkl"
            
            save_success = st.session_state.predictor.save_model(model_name)
            progress_bar.progress(100)
            
            if save_success:
                st.session_state.model_loaded = True
                status_text.text("âœ… Training completed!")
                
                st.success("ğŸ‰ Model training completed!")
                st.info(f"ğŸ“ Saved file: {model_name}")
                
                # è¨“ç·´çµæœã®è¡¨ç¤º
                if hasattr(st.session_state.predictor.trainer, 'performance_metrics'):
                    metrics = st.session_state.predictor.trainer.performance_metrics
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("ğŸ¯ Validation Accuracy", f"{metrics.get('val_accuracy', 0):.4f}")
                    with col2:
                        st.metric("ğŸ“ˆ AUC", f"{metrics.get('val_auc', 0):.4f}")
                    with col3:
                        st.metric("âš–ï¸ F1 Score", f"{metrics.get('val_f1', 0):.4f}")
                    with col4:
                        st.metric("ğŸª Recall", f"{metrics.get('val_recall', 0):.4f}")
                
            else:
                st.error("âŒ Failed to save model")
        else:
            st.error("âŒ Training failed")
        
        progress_bar.empty()
        status_text.empty()
        
    except Exception as e:
        st.error(f"âŒ Error during training: {str(e)}")
        progress_bar.empty()
        status_text.empty()

def estimate_training_time(n_trials):
    """è¨“ç·´æ™‚é–“ã®æ¨å®š"""
    # ç°¡æ˜“çš„ãªæ™‚é–“æ¨å®šï¼ˆè©¦è¡Œå›æ•°ã«åŸºã¥ãï¼‰
    base_time = 2  # åŸºæœ¬æ™‚é–“ï¼ˆåˆ†ï¼‰
    trial_time = n_trials * 0.5  # è©¦è¡Œå½“ãŸã‚Šã®æ™‚é–“ï¼ˆåˆ†ï¼‰
    total_minutes = base_time + trial_time
    
    if total_minutes < 60:
        return f"{total_minutes:.0f} minutes"
    else:
        hours = total_minutes // 60
        minutes = total_minutes % 60
        return f"{hours:.0f}h {minutes:.0f}m"

def model_comparison_tab():
    """ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚¿ãƒ–"""
    st.markdown("### ğŸ“ˆ Model Performance Comparison")
    
    models_info = list_saved_models('.')
    
    if not models_info:
        st.warning("No models available for comparison")
        return
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    selected_models = st.multiselect(
        "Select models to compare",
        options=[info['base_name'] for info in models_info],
        default=[info['base_name'] for info in models_info[:3]]  # æœ€å¤§3ã¤
    )
    
    if len(selected_models) < 2:
        st.info("Please select at least 2 models for comparison")
        return
    
    # æ¯”è¼ƒå®Ÿè¡Œ
    if st.button("ğŸ” Execute Comparison"):
        with st.spinner("Comparing models..."):
            # ã“ã“ã§å®Ÿéš›ã®æ¯”è¼ƒãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
            # ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
            comparison_data = []
            for model_name in selected_models:
                comparison_data.append({
                    'Model Name': model_name,
                    'Accuracy': np.random.uniform(0.75, 0.85),
                    'AUC': np.random.uniform(0.80, 0.90),
                    'F1 Score': np.random.uniform(0.70, 0.80),
                    'Training Time (min)': np.random.randint(30, 120)
                })
            
            df = pd.DataFrame(comparison_data)
            
            # æ¯”è¼ƒçµæœè¡¨ç¤º
            st.dataframe(df, use_container_width=True)
            
            # ã‚°ãƒ©ãƒ•è¡¨ç¤º
            fig = px.bar(
                df,
                x='Model Name',
                y=['Accuracy', 'AUC', 'F1 Score'],
                title="Model Performance Comparison",
                barmode='group'
            )
            st.plotly_chart(fig, use_container_width=True)

def return_analysis_tab():
    """å›åç‡åˆ†æã‚¿ãƒ–"""
    st.markdown("### ğŸ’° Return Rate Analysis")
    
    if not st.session_state.model_loaded:
        st.warning("Model loading required for return rate analysis")
        return
    
    if st.button("ğŸ“Š Execute Return Rate Simulation"):
        with st.spinner("Running simulation..."):
            try:
                # å›åç‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
                simulation_results = st.session_state.predictor.simulate_returns(
                    save_results=True
                )
                
                if simulation_results:
                    st.success("âœ… Simulation completed")
                    
                    # çµæœè¡¨ç¤º
                    fukusho_gain = simulation_results['fukusho_gain']
                    tansho_gain = simulation_results['tansho_gain']
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("#### ğŸ¥‰ Place Return Rate")
                        fig = px.line(
                            x=fukusho_gain.index,
                            y=fukusho_gain['return_rate'],
                            title="Place Return Rate Trend"
                        )
                        fig.add_hline(y=1.0, line_dash="dash", line_color="red")
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        st.markdown("#### ğŸ¥‡ Win Return Rate")
                        fig = px.line(
                            x=tansho_gain.index,
                            y=tansho_gain['return_rate'],
                            title="Win Return Rate Trend"
                        )
                        fig.add_hline(y=1.0, line_dash="dash", line_color="red")
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # æœ€é©é–¾å€¤ã®è¡¨ç¤º
                    best_fukusho = fukusho_gain.loc[fukusho_gain['return_rate'].idxmax()]
                    best_tansho = tansho_gain.loc[tansho_gain['return_rate'].idxmax()]
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric(
                            "ğŸ¥‰ Best Place Return Rate",
                            f"{best_fukusho['return_rate']:.3f}",
                            f"Threshold: {best_fukusho.name:.3f}"
                        )
                    
                    with col2:
                        st.metric(
                            "ğŸ¥‡ Best Win Return Rate",
                            f"{best_tansho['return_rate']:.3f}",
                            f"Threshold: {best_tansho.name:.3f}"
                        )
                
            except Exception as e:
                st.error(f"âŒ Simulation error: {str(e)}")

def prediction_history_tab():
    """äºˆæ¸¬å±¥æ­´ã‚¿ãƒ–"""
    st.markdown("### ğŸ“‹ Prediction History")
    
    # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å±¥æ­´ã‚’èª­ã¿è¾¼ã¿
    results_dir = Path("simulation_results")
    
    if not results_dir.exists():
        st.info("No prediction history available")
        return
    
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    json_files = list(results_dir.glob("prediction_*.json"))
    
    if not json_files:
        st.info("No prediction history found")
        return
    
    # å±¥æ­´ä¸€è¦§
    history_data = []
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            history_data.append({
                'File': json_file.name,
                'Race ID': data.get('race_id', 'N/A'),
                'Prediction Time': data.get('timestamp', 'N/A'),
                'Race Date': data.get('race_info', {}).get('date', 'N/A')
            })
        except:
            continue
    
    if history_data:
        df = pd.DataFrame(history_data)
        st.dataframe(df, use_container_width=True)
    else:
        st.info("No valid prediction history available")

def system_diagnostics_tab():
    """ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ã‚¿ãƒ–"""
    st.markdown("### ğŸ” System Diagnostics")
    
    # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
    checks = []
    
    # äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
    if st.session_state.predictor is not None:
        checks.append({"Item": "Prediction System", "Status": "âœ… Normal", "Details": "Initialized"})
    else:
        checks.append({"Item": "Prediction System", "Status": "âŒ Error", "Details": "Not initialized"})
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    if st.session_state.model_loaded:
        checks.append({"Item": "Model Loading", "Status": "âœ… Normal", "Details": "Loaded"})
    else:
        checks.append({"Item": "Model Loading", "Status": "âŒ Error", "Details": "Not loaded"})
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
    data_files = [
        "data/data/results.pickle",
        "data/data/horse_results.pickle",
        "data/data/peds.pickle"
    ]
    
    for file_path in data_files:
        if Path(file_path).exists():
            checks.append({"Item": f"Data File ({file_path})", "Status": "âœ… Exists", "Details": f"Size: {Path(file_path).stat().st_size:,} bytes"})
        else:
            checks.append({"Item": f"Data File ({file_path})", "Status": "âš ï¸ Missing", "Details": "File not found"})
    
    # çµæœè¡¨ç¤º
    df = pd.DataFrame(checks)
    st.dataframe(df, use_container_width=True, hide_index=True)
    
    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãªã©ã®è¿½åŠ æƒ…å ±
    st.markdown("#### ğŸ’» System Information")
    
    import psutil
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ’¾ Memory Usage", f"{psutil.virtual_memory().percent:.1f}%")
    
    with col2:
        st.metric("ğŸ’½ Disk Usage", f"{psutil.disk_usage('.').percent:.1f}%")
    
    with col3:
        st.metric("ğŸ–¥ï¸ CPU Usage", f"{psutil.cpu_percent():.1f}%")

if __name__ == "__main__":
    main()